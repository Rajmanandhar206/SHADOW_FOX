{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPRJ/LU41uo96VrHh8L7wzr",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Rajmanandhar206/SHADOW_FOX/blob/main/Autocorrection_Keyboard.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install pyspellchecker"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TbVl9Jbke0i7",
        "outputId": "d53759e0-5a79-492f-e695-d31e2e750220"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting pyspellchecker\n",
            "  Downloading pyspellchecker-0.8.2-py3-none-any.whl.metadata (9.4 kB)\n",
            "Downloading pyspellchecker-0.8.2-py3-none-any.whl (7.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.1/7.1 MB\u001b[0m \u001b[31m46.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: pyspellchecker\n",
            "Successfully installed pyspellchecker-0.8.2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "from collections import defaultdict, Counter\n",
        "from spellchecker import SpellChecker\n",
        "import math"
      ],
      "metadata": {
        "id": "oIOUplc9fLhn"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class AutocorrectKeyboard:\n",
        "    def __init__(self, ngram_n=3):\n",
        "        self.ngram_n = ngram_n  # Using trigrams by default\n",
        "        self.ngrams = defaultdict(Counter)\n",
        "        self.vocab = set()\n",
        "        self.spell = SpellChecker()\n",
        "        self.total_words = 0\n",
        "\n",
        "    def train(self, text_corpus):\n",
        "        \"\"\"Train the n-gram model on a text corpus\"\"\"\n",
        "        # Preprocess the text\n",
        "        sentences = self._preprocess_text(text_corpus)\n",
        "\n",
        "        # Build n-grams\n",
        "        for sentence in sentences:\n",
        "            words = sentence.split()\n",
        "            self.total_words += len(words)\n",
        "            self.vocab.update(words)\n",
        "\n",
        "            # Create n-grams of all orders up to ngram_n\n",
        "            for n in range(1, self.ngram_n + 1):\n",
        "                for i in range(len(words) - n + 1):\n",
        "                    context = tuple(words[i:i+n-1])\n",
        "                    next_word = words[i+n-1]\n",
        "                    self.ngrams[context][next_word] += 1\n",
        "\n",
        "    def _preprocess_text(self, text):\n",
        "        \"\"\"Clean and split text into sentences\"\"\"\n",
        "        # Convert to lowercase\n",
        "        text = text.lower()\n",
        "        # Remove special characters except basic punctuation\n",
        "        text = re.sub(r\"[^a-zA-Z0-9\\.,!?']\", \" \", text)\n",
        "        # Split into sentences (very simple split)\n",
        "        sentences = re.split(r\"[.!?]\", text)\n",
        "        # Remove empty sentences and strip whitespace\n",
        "        sentences = [s.strip() for s in sentences if s.strip()]\n",
        "        return sentences\n",
        ""
      ],
      "metadata": {
        "id": "dSNuY2_YfO2j"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        " def get_candidates(self, word):\n",
        "        \"\"\"Get spelling correction candidates for a word\"\"\"\n",
        "        # Known word - no correction needed\n",
        "        if word in self.vocab:\n",
        "            return [word]\n",
        "\n",
        "        # Get possible corrections\n",
        "        candidates = self.spell.candidates(word)\n",
        "        # Filter to only words in our vocabulary\n",
        "        vocab_candidates = [w for w in candidates if w in self.vocab] if candidates else []\n",
        "\n",
        "        # If no candidates found in vocab, try similar words\n",
        "        if not vocab_candidates:\n",
        "            similar_words = self.spell.correction(word)\n",
        "            if similar_words and similar_words in self.vocab:\n",
        "                vocab_candidates = [similar_words]\n",
        "\n",
        "        # If still no candidates, return the original word\n",
        "        return vocab_candidates if vocab_candidates else [word]\n",
        ""
      ],
      "metadata": {
        "id": "IotTlc-ufh-q"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def predict_next_word(self, previous_words, num_suggestions=3):\n",
        "        \"\"\"Predict the next word given previous words\"\"\"\n",
        "        if not previous_words:\n",
        "            return []\n",
        "\n",
        "        # Get the appropriate context (last n-1 words)\n",
        "        context = tuple(previous_words[-(self.ngram_n-1):]) if len(previous_words) >= self.ngram_n-1 else tuple(previous_words)\n",
        "\n",
        "        # Get possible next words and their counts\n",
        "        next_words = self.ngrams.get(context, Counter())\n",
        "\n",
        "        # Calculate probabilities (with smoothing)\n",
        "        total = sum(next_words.values()) + len(self.vocab)  # Add-one smoothing\n",
        "        suggestions = []\n",
        "\n",
        "        for word, count in next_words.most_common(num_suggestions):\n",
        "            prob = (count + 1) / total\n",
        "            suggestions.append((word, prob))\n",
        "\n",
        "        # If we don't have enough suggestions, back off to lower-order n-grams\n",
        "        if len(suggestions) < num_suggestions and len(context) > 1:\n",
        "            backoff_suggestions = self.predict_next_word(previous_words[1:], num_suggestions - len(suggestions))\n",
        "            suggestions.extend(backoff_suggestions)\n",
        "\n",
        "        # Remove duplicates and sort by probability\n",
        "        unique_suggestions = {}\n",
        "        for word, prob in suggestions:\n",
        "            if word not in unique_suggestions or prob > unique_suggestions[word]:\n",
        "                unique_suggestions[word] = prob\n",
        "\n",
        "        # Sort by probability and return top suggestions\n",
        "        sorted_suggestions = sorted(unique_suggestions.items(), key=lambda x: x[1], reverse=True)\n",
        "        return [word for word, prob in sorted_suggestions[:num_suggestions]]\n",
        ""
      ],
      "metadata": {
        "id": "qxV_LSq-fqJZ"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def process_input(self, text):\n",
        "        \"\"\"Process user input with autocorrect and predictions\"\"\"\n",
        "        words = text.lower().split()\n",
        "        if not words:\n",
        "            return {\"corrected_text\": \"\", \"next_word_predictions\": []}\n",
        "\n",
        "        # Autocorrect the last word\n",
        "        last_word = words[-1]\n",
        "        corrected_last_word = self.get_candidates(last_word)[0]\n",
        "\n",
        "        corrected_words = words[:-1] + [corrected_last_word]\n",
        "        corrected_text = \" \".join(corrected_words)\n",
        "\n",
        "        # Get next word predictions\n",
        "        predictions = self.predict_next_word(corrected_words)\n",
        "\n",
        "        return {\n",
        "            \"corrected_text\": corrected_text,\n",
        "            \"next_word_predictions\": predictions,\n",
        "            \"current_word_correction\": corrected_last_word if corrected_last_word != last_word else None\n",
        "        }\n"
      ],
      "metadata": {
        "id": "7QYMBn6Zf0uT"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "from collections import defaultdict, Counter\n",
        "\n",
        "class AutocorrectKeyboard:\n",
        "    def __init__(self, ngram_n=2):\n",
        "        self.ngram_n = ngram_n\n",
        "        self.ngrams = defaultdict(Counter)\n",
        "        self.vocab = set()\n",
        "        self.word_counts = Counter()\n",
        "\n",
        "    def train(self, text_corpus):\n",
        "        sentences = self._preprocess_text(text_corpus)\n",
        "\n",
        "        for sentence in sentences:\n",
        "            words = sentence.split()\n",
        "            self.vocab.update(words)\n",
        "            self.word_counts.update(words)\n",
        "\n",
        "            for i in range(len(words) - self.ngram_n + 1):\n",
        "                context = tuple(words[i:i+self.ngram_n-1])\n",
        "                next_word = words[i+self.ngram_n-1]\n",
        "                self.ngrams[context][next_word] += 1\n",
        "\n",
        "    def _preprocess_text(self, text):\n",
        "        text = text.lower()\n",
        "        text = re.sub(r\"[^a-z0-9\\s]\", \"\", text)\n",
        "        sentences = re.split(r\"[.!?]\", text)\n",
        "        return [s.strip() for s in sentences if s.strip()]\n",
        "\n",
        "    def _get_edit_distance(self, word1, word2):\n",
        "        if word1 == word2:\n",
        "            return 0\n",
        "        if len(word1) < len(word2):\n",
        "            return self._get_edit_distance(word2, word1)\n",
        "        if len(word2) == 0:\n",
        "            return len(word1)\n",
        "\n",
        "        previous_row = range(len(word2) + 1)\n",
        "        for i, c1 in enumerate(word1):\n",
        "            current_row = [i + 1]\n",
        "            for j, c2 in enumerate(word2):\n",
        "                insertions = previous_row[j + 1] + 1\n",
        "                deletions = current_row[j] + 1\n",
        "                substitutions = previous_row[j] + (c1 != c2)\n",
        "                current_row.append(min(insertions, deletions, substitutions))\n",
        "            previous_row = current_row\n",
        "\n",
        "        return previous_row[-1]\n",
        "\n",
        "    def get_correction(self, word):\n",
        "        if word in self.vocab:\n",
        "            return word\n",
        "\n",
        "        closest_word = min(\n",
        "            self.vocab,\n",
        "            key=lambda vocab_word: (\n",
        "                self._get_edit_distance(word, vocab_word),\n",
        "                -self.word_counts[vocab_word]\n",
        "            )\n",
        "        )\n",
        "\n",
        "        if self._get_edit_distance(word, closest_word) <= 2:\n",
        "            return closest_word\n",
        "        return word\n",
        "\n",
        "    def predict_next_word(self, previous_words, num_suggestions=3):\n",
        "        if not previous_words:\n",
        "            return []\n",
        "\n",
        "        context = tuple(previous_words[-(self.ngram_n-1):])\n",
        "        possible_words = self.ngrams.get(context, Counter())\n",
        "\n",
        "        suggestions = [word for word, count in possible_words.most_common(num_suggestions)]\n",
        "\n",
        "        if len(suggestions) < num_suggestions and len(context) > 0:\n",
        "            shorter_context = context[1:] if len(context) > 1 else tuple()\n",
        "            backoff_suggestions = self.predict_next_word(list(shorter_context),\n",
        "                                                       num_suggestions - len(suggestions))\n",
        "            suggestions.extend(backoff_suggestions)\n",
        "\n",
        "        return suggestions[:num_suggestions]\n",
        "\n",
        "    def process_input(self, text):\n",
        "        words = text.lower().split()\n",
        "        if not words:\n",
        "            return {\n",
        "                \"corrected_text\": \"\",\n",
        "                \"next_word_predictions\": [],\n",
        "                \"current_word_correction\": None\n",
        "            }\n",
        "\n",
        "        last_word = words[-1]\n",
        "        corrected_last_word = self.get_correction(last_word)\n",
        "\n",
        "        corrected_words = words[:-1] + [corrected_last_word]\n",
        "        corrected_text = \" \".join(corrected_words)\n",
        "\n",
        "        predictions = self.predict_next_word(corrected_words)\n",
        "\n",
        "        return {\n",
        "            \"corrected_text\": corrected_text,\n",
        "            \"next_word_predictions\": predictions,\n",
        "            \"current_word_correction\": corrected_last_word if corrected_last_word != last_word else None\n",
        "        }\n",
        "\n",
        "# Example usage with interactive input\n",
        "if __name__ == \"__main__\":\n",
        "    # Training corpus\n",
        "    corpus = \"\"\"\n",
        "    the quick brown fox jumps over the lazy dog\n",
        "    the quick fox is very fast the lazy dog sleeps all day\n",
        "    a quick brown dog can jump over fences the lazy fox watches\n",
        "    the quick and the lazy the quick brown fox is faster than the lazy dog\n",
        "    hello world this is a test of the autocorrect system\n",
        "    \"\"\"\n",
        "\n",
        "    keyboard = AutocorrectKeyboard(ngram_n=3)\n",
        "    keyboard.train(corpus)\n",
        "\n",
        "    print(\"Autocorrect Keyboard System\")\n",
        "    print(\"Type a sentence and press Enter (or 'quit' to exit)\")\n",
        "\n",
        "    while True:\n",
        "        user_input = input(\"\\nYour input: \").strip()\n",
        "        if user_input.lower() in ['quit', 'exit']:\n",
        "            break\n",
        "\n",
        "        result = keyboard.process_input(user_input)\n",
        "\n",
        "        print(\"\\nResults:\")\n",
        "        if result['current_word_correction']:\n",
        "            last_word = user_input.split()[-1]\n",
        "            print(f\"Corrected '{last_word}' to '{result['current_word_correction']}'\")\n",
        "\n",
        "        print(f\"Full corrected text: {result['corrected_text']}\")\n",
        "        print(\"Next word suggestions:\", \", \".join(result['next_word_predictions']))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 651
        },
        "id": "H_6D7KMoiRKM",
        "outputId": "6087e507-e531-4263-87b0-c8fca887fb17"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Autocorrect Keyboard System\n",
            "Type a sentence and press Enter (or 'quit' to exit)\n",
            "\n",
            "Your input: don\n",
            "\n",
            "Results:\n",
            "Corrected 'don' to 'dog'\n",
            "Full corrected text: dog\n",
            "Next word suggestions: \n",
            "\n",
            "Your input: sleop\n",
            "\n",
            "Results:\n",
            "Corrected 'sleop' to 'sleeps'\n",
            "Full corrected text: sleeps\n",
            "Next word suggestions: \n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "Interrupted by user",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-16-28dd40be2b27>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    122\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    123\u001b[0m     \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 124\u001b[0;31m         \u001b[0muser_input\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"\\nYour input: \"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstrip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    125\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0muser_input\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlower\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m'quit'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'exit'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    126\u001b[0m             \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/ipykernel/kernelbase.py\u001b[0m in \u001b[0;36mraw_input\u001b[0;34m(self, prompt)\u001b[0m\n\u001b[1;32m   1175\u001b[0m                 \u001b[0;34m\"raw_input was called, but this frontend does not support input requests.\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1176\u001b[0m             )\n\u001b[0;32m-> 1177\u001b[0;31m         return self._input_request(\n\u001b[0m\u001b[1;32m   1178\u001b[0m             \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprompt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1179\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_parent_ident\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"shell\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/ipykernel/kernelbase.py\u001b[0m in \u001b[0;36m_input_request\u001b[0;34m(self, prompt, ident, parent, password)\u001b[0m\n\u001b[1;32m   1217\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mKeyboardInterrupt\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1218\u001b[0m                 \u001b[0;31m# re-raise KeyboardInterrupt, to truncate traceback\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1219\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mKeyboardInterrupt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Interrupted by user\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1220\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1221\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlog\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwarning\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Invalid Message:\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexc_info\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: Interrupted by user"
          ]
        }
      ]
    }
  ]
}